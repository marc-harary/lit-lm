Map: 100%|████████████████████████████████████████████████████████████████████████| 4358/4358 [00:00<00:00, 5840.08 examples/s]
Map: 100%|██████████████████████████████████████████████████████████████████████| 36718/36718 [00:06<00:00, 5743.30 examples/s]
Map: 100%|████████████████████████████████████████████████████████████████████████| 3760/3760 [00:00<00:00, 5992.77 examples/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/ubuntu/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name  | Type            | Params | Mode
-------------------------------------------------
0 | model | GPT2LMHeadModel | 124 M  | eval
-------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.759   Total estimated model params size (MB)
0         Modules in train mode
164       Modules in eval mode
/home/ubuntu/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:527: Found 164 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.
Epoch 0:  14%|█████▉                                     | 633/4589 [01:54<11:56,  5.52it/s, v_num=tceq, train_loss_step=0.266]
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.

Detected KeyboardInterrupt, attempting graceful shutdown ...
